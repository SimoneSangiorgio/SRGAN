# SRGAN - Super Resolution Generative Adversarial Networks

## Code's Task
4x image upscaling
![SRGAN_Result3](https://github.com/SimoneSangiorgio/SRGAN/assets/169915445/e6ad1275-0d40-4ee9-a636-8c6d209c6d36)

## Architecture
![model](https://github.com/SimoneSangiorgio/SRGAN/assets/169915445/839b0edb-19cb-4384-8d23-e07aa82e1069)

## Dataset for Training and Test
DIV2K

## Mode of Use
The code has 3 modes of use:
- train: SRGAN uses the dataset to train a model
- evaluate: the trained model is evaluated
- generate: using the trained model, x4 upscaling of an image is performed
- 
### mode = 'train'
If the mode is ‘train’, both the discriminator and the generator are trained in each epoch.

1. The discriminator is trained on a batch of real images and a batch of images generated by the generator. Losses for both cases are calculated and then combined to obtain the discriminator's total loss.

2. The generator is then trained. A batch of low-resolution images and corresponding high-resolution images is provided. The high-resolution images are used to extract features using VGG19. Then, the loss of the generator is calculated using both the real labels and the extracted features. This loss is passed to the opponent model for training.
![download](https://github.com/SimoneSangiorgio/SRGAN/assets/169915445/dd247153-6ff3-4477-ae11-3f5979fb9460)

### mode = 'evaluate'
Compare the SRGAN model with other interpolation models used in image resizing using error metrics (PSNR, MSE).
We use the DIV2k Test set for evaluation. 
The methods chosen are:
- Bilinear interpolation: calculates the colour of each pixel of the new image as a weighted average of the four nearest pixels of the old image.
- Bicubic interpolation: uses the 16 closest pixels to calculate the colour of each new pixel as a weighted average with bicubic coefficients.
- Lanczos interpolation: technique based on the use of a sinc function

### mode = 'generate'
To implement the model in images larger than 64x64 and not square we will carry out a ‘decomposition and recomposition’ technique:

1. If the image is not square we will apply edge padding
2. We divide the selected image into many small 48x48 square patches.
3. We apply edge padding for each 48x48 square patch to create a 64x64 square patch (the generator can only work on 64x64 images)
4. The patches are upscaled
5. The upscaled patches are crop out and brought back to 48x48
6. The upscaled image is recomposed and the padding is cropped

If we used 64x64 images directly, because the trained model creates a slightly darker frame on the edge, at the end of the assembly process, we would have an image with a “tessellated” effect.



